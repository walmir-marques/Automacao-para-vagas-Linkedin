{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraindo dados de vagas do Linkedin através de Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalando as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests # Usada para fazer requisições HTTP, ou seja, acessar páginas da web e pegar seu conteúdo.\n",
    "!pip install beautifulsoup4 # Usada para processar e interpretar o código HTML das páginas da web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "\n",
    "import requests  # Para acessar páginas da web\n",
    "from bs4 import BeautifulSoup  # Para extrair informações do código HTML das páginas\n",
    "import pandas as pd  # Para criar e manipular tabelas de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coletando informações de filtros para a Vaga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_vaga = input(\"Digite o nome da vaga: \")\n",
    "nome_vaga_tratada = nome_vaga.replace(\" \", \"%20\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiencia = input(\"Digite o tipo de experiência: (0 = Todos, 1 = Estágio, 2 = Assistente, 3 = Júnior, 4 = Pleno-Sênior e 5 = Diretor)\")\n",
    "if experiencia == \"0\" or int(experiencia) > 5:\n",
    "    experiencia_tratada = ''\n",
    "else:\n",
    "    experiencia_tratada = f'''&f_E={experiencia}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_vaga = input(\"Digite o tipo da vaga: (0 = Todos, 1 = Presencial, 2 = Remoto, 3 = Híbrido)\")\n",
    "if tipo_vaga == \"0\" or int(tipo_vaga) > 3:\n",
    "    tipo_vaga_tratada = ''\n",
    "else:\n",
    "    tipo_vaga_tratada = f'''&f_WT={tipo_vaga}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a URL de busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = f'''\n",
    "https://www.linkedin.com/jobs/search?\n",
    "keywords={nome_vaga_tratada}\n",
    "&location=Brazil\n",
    "&geoId=106057199\n",
    "{experiencia_tratada}\n",
    "&f_TPR=r86400\n",
    "{tipo_vaga_tratada}\n",
    "&position=1\n",
    "&pageNum=0 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhttps://www.linkedin.com/jobs/search?\\nkeywords=analista%20de%20dados\\n&location=Brazil\\n&geoId=106057199\\n&f_E=2\\n&f_TPR=r86400\\n&f_WT=2\\n&position=1\\n&pageNum=0 \\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = base_url.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.linkedin.com/jobs/search?keywords=analista%20de%20dados&location=Brazil&geoId=106057199&f_E=2&f_TPR=r86400&f_WT=2&position=1&pageNum=0 '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo a requisição para o Linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo os dados da Página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encontrando os elementos com informações das vagas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = site.find_all(\"div\", attrs={\"class\" : \"base-card\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando uma lista para armazenar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "armazenando_vaga = []\n",
    "armazenamento_empresa = []\n",
    "armazenamento_localizacao = []\n",
    "armazenamento_tempo = []\n",
    "armazenamento_data = []\n",
    "armazenamento_link = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo informações de cada Vaga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for palavra in dados:\n",
    "  #Nome da vaga\n",
    "  nome_vaga = palavra.find_all(\"h3\", attrs = {\"class\": \"base-search-card__title\"})[0].text.strip()\n",
    "  armazenando_vaga.append(nome_vaga)\n",
    "\n",
    "\n",
    "  #nome empresa\n",
    "  nome_empresa = palavra.find_all(\"h4\", attrs = {\"class\": \"base-search-card__subtitle\"})[0].text.strip()\n",
    "  armazenamento_empresa.append(nome_empresa)\n",
    "\n",
    "\n",
    "  #Localização\n",
    "\n",
    "  localizacao = palavra.find_all(\"span\", attrs = {\"class\": \"job-search-card__location\"})[0].text.strip()\n",
    "  armazenamento_localizacao.append(localizacao)\n",
    "\n",
    "  #Tempo disponibilidade da vaga\n",
    "  tempo_vaga = palavra.find_all(\"time\")[0].text.strip()\n",
    "  armazenamento_tempo.append(tempo_vaga)\n",
    "\n",
    "  #data \n",
    "  data = palavra.find_all(\"time\", attrs = {\"class\": \"job-search-card__listdate--new\"})[0]\n",
    "  data_trat = data[\"datetime\"]\n",
    "  armazenamento_data.append(data_trat)\n",
    "\n",
    "  # se quiser em uma linha só: data_trat = palavra.find_all(\"time\")[0].get('datetime')\n",
    "  # ou data_trat = palavra.find_all(\"time\")[0][\"datetime\"]\n",
    "\n",
    "  #Link da vaga \n",
    "  link_vaga = palavra.find_all(\"a\", attrs = {\"class\": \"base-card__full-link\"})[0].get('href')\n",
    "  armazenamento_link.append(link_vaga)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um dicionário com os dados coletados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vagas = {\n",
    "\"Vaga\" : armazenando_vaga,\n",
    "\"Empresa\": armazenamento_empresa,\n",
    "\"Localizacao\" : armazenamento_localizacao,\n",
    "\"Tempo_postada\": armazenamento_tempo,\n",
    "\"Data da Vaga\" : armazenamento_data,\n",
    "\"Link da Vaga\" : armazenamento_link\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando um dataframe para armazenar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(base_vagas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vaga</th>\n",
       "      <th>Empresa</th>\n",
       "      <th>Localizacao</th>\n",
       "      <th>Tempo_postada</th>\n",
       "      <th>Data da Vaga</th>\n",
       "      <th>Link da Vaga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desenvolvedor SQL Server (T-SQL)</td>\n",
       "      <td>Grupo Adriano Cobuccio</td>\n",
       "      <td>Monte Belo, Minas Gerais, Brazil</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/desenvolvedo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Engenheiro de dados junior</td>\n",
       "      <td>Netvagas</td>\n",
       "      <td>São Paulo, São Paulo, Brazil</td>\n",
       "      <td>15 hours ago</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/engenheiro-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Research Assistant</td>\n",
       "      <td>Alana AI</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>2025-02-07</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/research-ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analista de Desenvolvimento - Pleno</td>\n",
       "      <td>Implanta IT Solutions</td>\n",
       "      <td>Goiânia, Goiás, Brazil</td>\n",
       "      <td>21 hours ago</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/analista-de-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANALISTA DE DESENVOLVIMENTO II</td>\n",
       "      <td>G4F</td>\n",
       "      <td>Salvador, Bahia, Brazil</td>\n",
       "      <td>19 hours ago</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/analista-de-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>Turing</td>\n",
       "      <td>Porto Alegre, Rio Grande do Sul, Brazil</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>Turing</td>\n",
       "      <td>São Paulo, São Paulo, Brazil</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>Turing</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>Turing</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Data Scientist/Analyst</td>\n",
       "      <td>Turing</td>\n",
       "      <td>Porto Alegre, Rio Grande do Sul, Brazil</td>\n",
       "      <td>22 hours ago</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>https://br.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Vaga                 Empresa  \\\n",
       "0       Desenvolvedor SQL Server (T-SQL)  Grupo Adriano Cobuccio   \n",
       "1             Engenheiro de dados junior                Netvagas   \n",
       "2                     Research Assistant                Alana AI   \n",
       "3    Analista de Desenvolvimento - Pleno   Implanta IT Solutions   \n",
       "4         ANALISTA DE DESENVOLVIMENTO II                     G4F   \n",
       "..                                   ...                     ...   \n",
       "111               Data Scientist/Analyst                  Turing   \n",
       "112               Data Scientist/Analyst                  Turing   \n",
       "113               Data Scientist/Analyst                  Turing   \n",
       "114               Data Scientist/Analyst                  Turing   \n",
       "115               Data Scientist/Analyst                  Turing   \n",
       "\n",
       "                                 Localizacao Tempo_postada Data da Vaga  \\\n",
       "0           Monte Belo, Minas Gerais, Brazil   9 hours ago   2025-02-07   \n",
       "1               São Paulo, São Paulo, Brazil  15 hours ago   2025-02-07   \n",
       "2                                     Brazil   2 hours ago   2025-02-07   \n",
       "3                     Goiânia, Goiás, Brazil  21 hours ago   2025-02-06   \n",
       "4                    Salvador, Bahia, Brazil  19 hours ago   2025-02-06   \n",
       "..                                       ...           ...          ...   \n",
       "111  Porto Alegre, Rio Grande do Sul, Brazil  22 hours ago   2025-02-06   \n",
       "112             São Paulo, São Paulo, Brazil  22 hours ago   2025-02-06   \n",
       "113                                   Brazil  22 hours ago   2025-02-06   \n",
       "114                                   Brazil  22 hours ago   2025-02-06   \n",
       "115  Porto Alegre, Rio Grande do Sul, Brazil  22 hours ago   2025-02-06   \n",
       "\n",
       "                                          Link da Vaga  \n",
       "0    https://br.linkedin.com/jobs/view/desenvolvedo...  \n",
       "1    https://br.linkedin.com/jobs/view/engenheiro-d...  \n",
       "2    https://br.linkedin.com/jobs/view/research-ass...  \n",
       "3    https://br.linkedin.com/jobs/view/analista-de-...  \n",
       "4    https://br.linkedin.com/jobs/view/analista-de-...  \n",
       "..                                                 ...  \n",
       "111  https://br.linkedin.com/jobs/view/data-scienti...  \n",
       "112  https://br.linkedin.com/jobs/view/data-scienti...  \n",
       "113  https://br.linkedin.com/jobs/view/data-scienti...  \n",
       "114  https://br.linkedin.com/jobs/view/data-scienti...  \n",
       "115  https://br.linkedin.com/jobs/view/data-scienti...  \n",
       "\n",
       "[116 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximos passos, Fazer a inclusão dos daos em um banco de dados e subir para a AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
